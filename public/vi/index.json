[
{
	"uri": "//localhost:1313/vi/3-migrate/3.3-k8s-app/3.3.1-alb-ingress-controller/",
	"title": "AWS ALB Ingress Controller",
	"tags": [],
	"description": "",
	"content": "Tại thời điểm này, Ứng dụng Phonebook đã được triển khai trong private subnet, vì vậy nếu cần đưa Ứng dụng ra Internet, chúng ta cần triển khai bộ cân bằng tải AWS trong public subnet trỏ tới App Phonebook trong private subnet.\nAmazon Application Load Balancer (ALB) là một dịch vụ AWS phổ biến giúp cân bằng tải lưu lượng truy cập đến ở lớp ứng dụng (layer 7) trên nhiều target, chẳng hạn như phiên bản Amazon EC2, trong một khu vực. ALB hỗ trợ nhiều tính năng bao gồm định tuyến dựa trên máy chủ hoặc đường dẫn, chấm dứt TLS (Transport Layer Security), WebSockets, HTTP/2, tích hợp AWS WAF (Web Application Firewall), tích hợp logs và healthy check.\nKubernetes Ingress là tài nguyên API cho phép bạn quản lý quyền truy cập HTTP(S) bên ngoài hoặc nội bộ vào các dịch vụ Kubernetes chạy trong một cụm\nALB Ingress Controller là mã nguồn mở kích hoạt việc tạo ALB và các tài nguyên AWS hỗ trợ cần thiết bất cứ khi nào người dùng Kubernetes khai báo tài nguyên Ingress trong cụm. Tài nguyên Ingress sử dụng ALB để định tuyến lưu lượng HTTP(S) đến các điểm cuối khác nhau trong cụm. Ingress Controller Ingress AWS ALB hoạt động trên mọi cụm Kubernetes, bao gồm cả Amazon Elastic Kubernetes Service (Amazon EKS).\nCách thức hoạt động của AWS Load Balancer controller:\n[1]: Ingress Controller theo dõi các sự kiện Ingress từ API server. Khi tìm thấy tài nguyên Ingress đáp ứng yêu cầu của mình, nó sẽ bắt đầu tạo tài nguyên AWS.\n[2]: ALB (ELBv2) được tạo trong AWS cho Ingress resource mới. ALB này có thể truy cập internet hoặc nội bộ. Bạn cũng có thể chỉ định các mạng con được tạo bằng cách sử dụng chú thích.\n[3]: Nhóm mục tiêu được tạo trong AWS cho từng dịch vụ Kubernetes duy nhất được mô tả trong tài nguyên đầu vào.\n[4]: Trình nghe được tạo cho mọi cổng được nêu chi tiết trong chú thích tài nguyên đầu vào của bạn. Khi không có cổng nào được chỉ định, các giá trị mặc định hợp lý (80 hoặc 443) sẽ được sử dụng. Chứng chỉ cũng có thể được đính kèm thông qua chú thích.\n[5]: Các quy tắc được tạo cho từng đường dẫn được chỉ định trong Ingress resource của bạn. Điều này đảm bảo lưu lượng truy cập đến một đường dẫn cụ thể được chuyển đến Dịch vụ Kubernetes chính xác.\nNgoài những điều trên, Ingress Controller còn\u0026hellip;\nXóa các thành phần AWS khi Ingress resource bị xóa khỏi k8. Sửa đổi các thành phần AWS khi Ingress resource thay đổi theo k8. Tập hợp danh sách các thành phần AWS liên quan đến hoạt động Ingress hiện có khi khởi động, cho phép bạn khôi phục nếu Ingress Controller được khởi động lại. Ingress Controller Cân bằng tải AWS hỗ trợ hai chế độ lưu lượng:\nChế độ Instance: Lưu lượng truy cập bắt đầu tại ALB và đến các nút Kubernetes thông qua NodePort của mỗi dịch vụ. Điều này có nghĩa là các dịch vụ được tham chiếu từ Ingress resource phải được hiển thị theo type:NodePort để ALB có thể tiếp cận. Chế độ IP: Lưu lượng truy cập bắt đầu tại ALB và đến trực tiếp các nhóm Kubernetes. CNI phải hỗ trợ ip POD có thể truy cập trực tiếp qua địa chỉ IP phụ trên ENI (Tham khảo: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-eni.html) Theo mặc định, chế độ Phiên bản được sử dụng, người dùng có thể chọn chế độ này một cách rõ ràng thông qua chú thích alb.ingress.kubernetes.io/target-type. Cài đặt AWS ALB Ingress Controller:\nStep 1: Tạo Kubernetes RBAC role \u0026amp; Service Account cho ALB Ingress Controller.\nTạo manifest file để tạo permission cho aws-load-balancer-controller, sau đó apply nó\ncat \u0026lt;\u0026lt;EOF \u0026gt; rbac-role-aws-load-balancer-controller.yaml\r---\rapiVersion: rbac.authorization.k8s.io/v1\rkind: ClusterRole\rmetadata:\rlabels:\rapp.kubernetes.io/name: aws-load-balancer-controller\rname: aws-load-balancer-controller\rrules:\r- apiGroups:\r- \u0026quot;\u0026quot;\r- extensions\rresources:\r- configmaps\r- endpoints\r- events\r- ingresses\r- ingresses/status\r- services\r- pods/status\rverbs:\r- create\r- get\r- list\r- update\r- watch\r- patch\r- apiGroups:\r- \u0026quot;\u0026quot;\r- extensions\rresources:\r- nodes\r- pods\r- secrets\r- services\r- namespaces\rverbs:\r- get\r- list\r- watch\r---\rapiVersion: rbac.authorization.k8s.io/v1\rkind: ClusterRoleBinding\rmetadata:\rlabels:\rapp.kubernetes.io/name: aws-load-balancer-controller\rname: aws-load-balancer-controller\rroleRef:\rapiGroup: rbac.authorization.k8s.io\rkind: ClusterRole\rname: aws-load-balancer-controller\rsubjects:\r- kind: ServiceAccount\rname: aws-load-balancer-controller\rnamespace: kube-system\r---\rapiVersion: v1\rkind: ServiceAccount\rmetadata:\rlabels:\rapp.kubernetes.io/name: aws-load-balancer-controller\rname: aws-load-balancer-controller\rnamespace: kube-system\r...\rEOF\rkubectl apply -f rbac-role-aws-load-balancer-controller.yaml\rStep 2. Tạo IAM Policy cho ALB Ingress Controller\nChính sách IAM này sẽ cho phép ALB Controller Ingress thực hiện lệnh gọi tới API AWS\nStep 2.1: Go to IAM Service: https://us-east-1.console.aws.amazon.com/iam/home?region=us-east-1\nStep 2.2: Select Policies, then click to Create Policies: Step 2.3: Nhập policy for ALB Ingress Controller như sau:\n{\r\u0026quot;Version\u0026quot;: \u0026quot;2012-10-17\u0026quot;,\r\u0026quot;Statement\u0026quot;: [\r{\r\u0026quot;Effect\u0026quot;: \u0026quot;Allow\u0026quot;,\r\u0026quot;Action\u0026quot;: [\r\u0026quot;acm:DescribeCertificate\u0026quot;,\r\u0026quot;acm:ListCertificates\u0026quot;,\r\u0026quot;acm:GetCertificate\u0026quot;,\r\u0026quot;ec2:*\u0026quot;\r],\r\u0026quot;Resource\u0026quot;: \u0026quot;*\u0026quot;\r},\r{\r\u0026quot;Effect\u0026quot;: \u0026quot;Allow\u0026quot;,\r\u0026quot;Action\u0026quot;: [\r\u0026quot;ec2:AuthorizeSecurityGroupIngress\u0026quot;,\r\u0026quot;ec2:CreateSecurityGroup\u0026quot;,\r\u0026quot;ec2:CreateTags\u0026quot;,\r\u0026quot;ec2:DeleteTags\u0026quot;,\r\u0026quot;ec2:DeleteSecurityGroup\u0026quot;,\r\u0026quot;ec2:DescribeAccountAttributes\u0026quot;,\r\u0026quot;ec2:DescribeAddresses\u0026quot;,\r\u0026quot;ec2:DescribeInstances\u0026quot;,\r\u0026quot;ec2:DescribeInstanceStatus\u0026quot;,\r\u0026quot;ec2:DescribeInternetGateways\u0026quot;,\r\u0026quot;ec2:DescribeNetworkInterfaces\u0026quot;,\r\u0026quot;ec2:DescribeSecurityGroups\u0026quot;,\r\u0026quot;ec2:DescribeSubnets\u0026quot;,\r\u0026quot;ec2:DescribeTags\u0026quot;,\r\u0026quot;ec2:DescribeVpcs\u0026quot;,\r\u0026quot;ec2:ModifyInstanceAttribute\u0026quot;,\r\u0026quot;ec2:ModifyNetworkInterfaceAttribute\u0026quot;,\r\u0026quot;ec2:RevokeSecurityGroupIngress\u0026quot;\r],\r\u0026quot;Resource\u0026quot;: \u0026quot;*\u0026quot;\r},\r{\r\u0026quot;Effect\u0026quot;: \u0026quot;Allow\u0026quot;,\r\u0026quot;Action\u0026quot;: [\r\u0026quot;elasticloadbalancing:AddListenerCertificates\u0026quot;,\r\u0026quot;elasticloadbalancing:AddTags\u0026quot;,\r\u0026quot;elasticloadbalancing:CreateListener\u0026quot;,\r\u0026quot;elasticloadbalancing:CreateLoadBalancer\u0026quot;,\r\u0026quot;elasticloadbalancing:CreateRule\u0026quot;,\r\u0026quot;elasticloadbalancing:CreateTargetGroup\u0026quot;,\r\u0026quot;elasticloadbalancing:DeleteListener\u0026quot;,\r\u0026quot;elasticloadbalancing:DeleteLoadBalancer\u0026quot;,\r\u0026quot;elasticloadbalancing:DeleteRule\u0026quot;,\r\u0026quot;elasticloadbalancing:DeleteTargetGroup\u0026quot;,\r\u0026quot;elasticloadbalancing:DeregisterTargets\u0026quot;,\r\u0026quot;elasticloadbalancing:DescribeListenerCertificates\u0026quot;,\r\u0026quot;elasticloadbalancing:DescribeListeners\u0026quot;,\r\u0026quot;elasticloadbalancing:DescribeLoadBalancers\u0026quot;,\r\u0026quot;elasticloadbalancing:DescribeLoadBalancerAttributes\u0026quot;,\r\u0026quot;elasticloadbalancing:DescribeRules\u0026quot;,\r\u0026quot;elasticloadbalancing:DescribeSSLPolicies\u0026quot;,\r\u0026quot;elasticloadbalancing:DescribeTags\u0026quot;,\r\u0026quot;elasticloadbalancing:DescribeTargetGroups\u0026quot;,\r\u0026quot;elasticloadbalancing:DescribeTargetGroupAttributes\u0026quot;,\r\u0026quot;elasticloadbalancing:DescribeTargetHealth\u0026quot;,\r\u0026quot;elasticloadbalancing:ModifyListener\u0026quot;,\r\u0026quot;elasticloadbalancing:ModifyLoadBalancerAttributes\u0026quot;,\r\u0026quot;elasticloadbalancing:ModifyRule\u0026quot;,\r\u0026quot;elasticloadbalancing:ModifyTargetGroup\u0026quot;,\r\u0026quot;elasticloadbalancing:ModifyTargetGroupAttributes\u0026quot;,\r\u0026quot;elasticloadbalancing:RegisterTargets\u0026quot;,\r\u0026quot;elasticloadbalancing:RemoveListenerCertificates\u0026quot;,\r\u0026quot;elasticloadbalancing:RemoveTags\u0026quot;,\r\u0026quot;elasticloadbalancing:SetIpAddressType\u0026quot;,\r\u0026quot;elasticloadbalancing:SetSecurityGroups\u0026quot;,\r\u0026quot;elasticloadbalancing:SetSubnets\u0026quot;,\r\u0026quot;elasticloadbalancing:SetWebAcl\u0026quot;\r],\r\u0026quot;Resource\u0026quot;: \u0026quot;*\u0026quot;\r},\r{\r\u0026quot;Effect\u0026quot;: \u0026quot;Allow\u0026quot;,\r\u0026quot;Action\u0026quot;: [\r\u0026quot;iam:CreateServiceLinkedRole\u0026quot;,\r\u0026quot;iam:GetServerCertificate\u0026quot;,\r\u0026quot;iam:ListServerCertificates\u0026quot;\r],\r\u0026quot;Resource\u0026quot;: \u0026quot;*\u0026quot;\r},\r{\r\u0026quot;Effect\u0026quot;: \u0026quot;Allow\u0026quot;,\r\u0026quot;Action\u0026quot;: [\r\u0026quot;cognito-idp:DescribeUserPoolClient\u0026quot;,\r\u0026quot;eks:*\u0026quot;\r],\r\u0026quot;Resource\u0026quot;: \u0026quot;*\u0026quot;\r},\r{\r\u0026quot;Effect\u0026quot;: \u0026quot;Allow\u0026quot;,\r\u0026quot;Action\u0026quot;: [\r\u0026quot;waf-regional:GetWebACLForResource\u0026quot;,\r\u0026quot;waf-regional:GetWebACL\u0026quot;,\r\u0026quot;waf-regional:AssociateWebACL\u0026quot;,\r\u0026quot;waf-regional:DisassociateWebACL\u0026quot;\r],\r\u0026quot;Resource\u0026quot;: \u0026quot;*\u0026quot;\r},\r{\r\u0026quot;Effect\u0026quot;: \u0026quot;Allow\u0026quot;,\r\u0026quot;Action\u0026quot;: [\r\u0026quot;tag:GetResources\u0026quot;,\r\u0026quot;tag:TagResources\u0026quot;\r],\r\u0026quot;Resource\u0026quot;: \u0026quot;*\u0026quot;\r},\r{\r\u0026quot;Effect\u0026quot;: \u0026quot;Allow\u0026quot;,\r\u0026quot;Action\u0026quot;: [\r\u0026quot;waf:GetWebACL\u0026quot;\r],\r\u0026quot;Resource\u0026quot;: \u0026quot;*\u0026quot;\r},\r{\r\u0026quot;Effect\u0026quot;: \u0026quot;Allow\u0026quot;,\r\u0026quot;Action\u0026quot;: [\r\u0026quot;wafv2:GetWebACL\u0026quot;,\r\u0026quot;wafv2:GetWebACLForResource\u0026quot;,\r\u0026quot;wafv2:AssociateWebACL\u0026quot;,\r\u0026quot;wafv2:DisassociateWebACL\u0026quot;\r],\r\u0026quot;Resource\u0026quot;: \u0026quot;*\u0026quot;\r},\r{\r\u0026quot;Effect\u0026quot;: \u0026quot;Allow\u0026quot;,\r\u0026quot;Action\u0026quot;: [\r\u0026quot;shield:DescribeProtection\u0026quot;,\r\u0026quot;shield:GetSubscriptionState\u0026quot;,\r\u0026quot;shield:DeleteProtection\u0026quot;,\r\u0026quot;shield:CreateProtection\u0026quot;,\r\u0026quot;shield:DescribeSubscription\u0026quot;,\r\u0026quot;shield:ListProtections\u0026quot;\r],\r\u0026quot;Resource\u0026quot;: \u0026quot;*\u0026quot;\r}\r]\r}\rStep 2.4: Click vào Create Policy\nStep 3: Tạo IAM role cho ALB Ingress Controller sau đó attach role đến service account\neksctl create iamserviceaccount \\\r--region us-east-1 \\\r--name aws-load-balancer-controller \\\r--namespace kube-system \\\r--cluster phonebook-eks-cluster \\\r--attach-policy-arn arn:aws:iam::413403005747:policy/ALBIngressControllerIAMPolicy \\\r--override-existing-serviceaccounts \\\r--approve\rStep 4: Cài đặt cert-manager\ncert-manager là một addon Kubernetes để tự động hóa việc quản lý và cấp Cert TLS từ nhiều nguồn phát hành khác nhau. Nó sẽ đảm bảo các chứng chỉ có giá trị và được cập nhật định kỳ, đồng thời cố gắng gia hạn chứng chỉ vào thời điểm thích hợp trước khi hết hạn.\nkubectl apply --validate=false -f https://github.com/jetstack/cert-manager/releases/download/v1.12.3/cert-manager.yaml\rStep 5: Triển khai ALB Ingress Controller\nDownload the manifest file for the ALB Ingress Controller\nwget https://github.com/kubernetes-sigs/aws-load-balancer-controller/releases/download/v2.7.0/v2_7_0_full.yaml\rChỉnh sửa tệp yaml đã lưu, đi tới Deployment spec và set controller giá trị \u0026ndash;cluster-name arg thành EKS cluster\napiVersion: apps/v1\rkind: Deployment\r. . .\rname: aws-load-balancer-controller\rnamespace: kube-system\rspec:\r. . .\rtemplate:\rspec:\rcontainers:\r- args:\r- --cluster-name=\u0026lt;your-cluster-name\u0026gt;\rNếu bạn sử dụng IAM role cho service account, Nên xóa ServiceAccount khỏi thông số yaml. Nếu xóa phần cài đặt khỏi thông số yaml, việc xóa ServiceAccount sẽ giữ nguyên eksctl đã tạo iamserviceaccoun Áp dụng tệp yaml:\nkubectl apply -f v2_7_0_full.yaml\rTa đã cài đặt thành công AWS ALB Ingress Controller: "
},
{
	"uri": "//localhost:1313/vi/4-backup-restore/4.1-backup/",
	"title": "Backup mysql database trên môi trường On-premsise",
	"tags": [],
	"description": "",
	"content": "Run command để access vào MySQL Pod:\nkubectcl exec –it \u0026lt;mysql_pod\u0026gt; bash –n phonebook\rRun command để backup:\nmysqldump -u root -p phonebook \u0026gt; /var/lib/mysql/database_phonebook.sql\rVì thư mục /var/lib/mysql trong pod mysql được mount với thư mục /mnt/data trên server nên chúng ta có thể thấy file database_phonebook.sql trong thư mục /mnt/data trên server.\n"
},
{
	"uri": "//localhost:1313/vi/1-problem/",
	"title": "Đặt vấn đề",
	"tags": [],
	"description": "",
	"content": "Một công ty XYZ đã triển khai Service của họ bằng nền tảng Kubernetes trên môi trường On-premsise. Tuy nhiên, sau một thời gian, Công ty nhận thấy nhiều vấn đề về việc vận hành, như phải tự quản lý cơ sở hạ tầng, cần đảm bảo tính sẵn sàng cao cho Control Plane, Etcd, v.v. nên mất rất nhiều thời gian và nguồn nhân lực.\nTrong bối cảnh đó, team DevOps đã nhận được yêu cầu từ Leadership về sự kiện đặc biệt của công ty, khi được dự đoán số lượng request tới Service sẽ tăng gấp 3 lần. Team DevOps đã kiểm tra rằng tài nguyên hiện tại khó đáp ứng được yêu cầu tăng gấp 3 lần trong sự kiện đặc biệt của công ty. Do đó, để giải quyết vấn đề mở rộng nhanh chóng và tiết kiệm chi phí, team DevOps phải dự đoán và đưa ra phương án dự phòng cho nhu cầu mở rộng, bao gồm mua thêm bao nhiêu server, mở rộng cơ sở hạ tầng mạng và tăng dung lượng lưu trữ..v.v. Quá trình mở rộng quy mô này có thể tốn kém và mất thời gian, chưa kể khi kết thúc sự kiện sẽ có một lượng lớn tài nguyên nhàn rỗi không được sử dụng.\nDo đó, team DevOps đã quyết định di chuyển service lên môi trường Cloud để nhận được những benefits sau:\nTính mở rộng linh hoạt: Cloud cho phép ta mở rộng quy mô tài nguyên khi cần mà không cần phải đầu tư vào phần cứng và cơ sở hạ tầng. Ta có thể dễ dàng tăng hoặc giảm số lượng server để đáp ứng khối lượng công việc. Mở rộng linh hoạt giúp tiết kiệm chi phí và tối ưu hóa việc sử dụng tài nguyên. Đơn giản hóa quản lý cơ sở hạ tầng: CLoud loại bỏ khó khăn và công việc liên quan đến việc quản lý cơ sở hạ tầng Kubernetes. AWS quản lý và duy trì toàn bộ cơ sở hạ tầng, bao gồm cài đặt, định cấu hình, thay đổi quy mô và nâng cấp các thành phần Kubernetes. Điều này giúp giảm bớt gánh nặng quản lý và giúp ta tập trung vào phát triển ứng dụng. Tích hợp dịch vụ AWS: CLoud tích hợp tốt với các dịch vụ và công cụ AWS khác. ta có thể sử dụng các dịch vụ như Amazon EC2, Amazon RDS, Amazon S3, Amazon DynamoDB..v..v để bổ sung cho ứng dụng của mình. Điều này giúp thúc đẩy các dịch vụ quản lý cơ sở dữ liệu, lưu trữ và xử lý dữ liệu, giảm thiểu công việc tích hợp và tăng độ tin cậy của hệ thống. Chi phí linh hoạt: Di chuyển từ môi trường On-premsise sang Cloud giúp ta chuyển từ mô hình trả trước (CAPEX) sang mô hình trả theo mức sử dụng (OPEX). Thay vì phải đầu tư vào phần cứng và cơ sở hạ tầng, ta chỉ trả tiền để sử dụng dịch vụ theo mô hình pay-as-you-go. Điều này giúp ta tối ưu hóa chi phí và linh hoạt trong việc phát triển và vận hành ứng dụng. Workshop này tập trung vào việc demo di chuyển một ứng dụng Micro-service Phonebook đơn giản được triển khai trên cụm Kubernetes trong môi trường On-premsise lên môi trường AWS Cloud, cũng như xây dựng kiến trúc cụm EKS bằng cách sử dụng tool Infrastrure as code là Terraform. Workshop không bao gồm CI/CD, monitoring, logging hay tích hợp các dịch vụ AWS khác như RDS, Cloudwatch, v.v.\n"
},
{
	"uri": "//localhost:1313/vi/2-architecture/2.1-on-prem/",
	"title": "Kiến trúc hiện tại của hệ thống Kubernetes trên môi trường on-premises",
	"tags": [],
	"description": "",
	"content": "Content Kiến trúc cụm Kubernetes trên môi trường on-premises Kiến trúc ứng dụng được triển khai bằng Kubernetes trên môi trường on-premises "
},
{
	"uri": "//localhost:1313/vi/2-architecture/2.1-on-prem/2.1.1-k8s-cluster/",
	"title": "Kubernetes cluster architecture on On-premises environment",
	"tags": [],
	"description": "",
	"content": "\nKiến trúc này đảm bảo High Availability nên có 3 Server Control Plane với một cụm external etcd gồm 3 Server, 2 Server chịu trách nhiệm cân bằng tải theo mô hình active-standby và Worker node. Vì vậy trên mô hình On-Premise chúng ta phải quản lý toàn bộ kiến trúc như trên và xử lý các sự cố xảy ra, luôn đảm bảo tính High Availability và đảm nhiệm các kịch bản backup \u0026amp; recovery cho Infra khi có sự cố xảy ra.\n"
},
{
	"uri": "//localhost:1313/vi/",
	"title": "Overall",
	"tags": [],
	"description": "",
	"content": "Di chuyển service được triển khai bằng Kubernetes từ môi trường on-premises sang môi trường Cloud Overall Workshop này trình bày cách di chuyển ứng dụng Micro-service Phonebook đơn giản được triển khai bằng Kubernetes trên môi trường on-premises sang môi trường AWS Cloud, cũng như xây dựng kiến trúc cụm EKS bằng cách sử dụng tool Infrastrure as code là Terraform\nContent Đặt vấn đề Kiến trúc Di chuyển service từ môi trường on-premises sang môi trường Cloud Backup \u0026amp; restore dữ liệu ứng dụng từ môi trường on-premises lên AWS cloud Dọn dẹp tài nguyên "
},
{
	"uri": "//localhost:1313/vi/3-migrate/3.2-terraform/3.2.1-vpc-subnet/",
	"title": "Tạo AWS VPC &amp; Subnets bằng cách sử dụng Terraform",
	"tags": [],
	"description": "",
	"content": "Bước tiếp theo là tạo virtual private cloud sử dụng \u0026ldquo;aws_vpc\u0026rdquo; trong Terraform. TCó một trường bắt buộc cần cung cấp, đó là kích thước mạng.\nSau đó, tạo 2 public subnets và 2 private subnets:\n# Create VPC\rresource \u0026quot;aws_vpc\u0026quot; \u0026quot;vpc-main\u0026quot; {\rcidr_block = \u0026quot;10.10.0.0/16\u0026quot;\renable_dns_hostnames = true\renable_dns_support = true\rtags = {\rName = \u0026quot;vpc-main\u0026quot;\r}\r}\routput \u0026quot;aws_vpc\u0026quot; {\rvalue = aws_vpc.vpc-main.id\r}\r# Create Subnet\rresource \u0026quot;aws_subnet\u0026quot; \u0026quot;public-subnet-vpc-main-1\u0026quot; {\rvpc_id = aws_vpc.vpc-main.id\rcidr_block = \u0026quot;10.10.1.0/24\u0026quot;\ravailability_zone = \u0026quot;us-east-1a\u0026quot;\rmap_public_ip_on_launch = true\rtags = {\rName = \u0026quot;public-subnet-vpc-main-1\u0026quot;\r}\r}\rresource \u0026quot;aws_subnet\u0026quot; \u0026quot;public-subnet-vpc-main-2\u0026quot; {\rvpc_id = aws_vpc.vpc-main.id\rcidr_block = \u0026quot;10.10.2.0/24\u0026quot;\ravailability_zone = \u0026quot;us-east-1b\u0026quot;\rmap_public_ip_on_launch = true\rtags = {\rName = \u0026quot;public-subnet-vpc-main-2\u0026quot;\r}\r}\rresource \u0026quot;aws_subnet\u0026quot; \u0026quot;private-subnet-vpc-main-1\u0026quot; {\rvpc_id = aws_vpc.vpc-main.id\rcidr_block = \u0026quot;10.10.3.0/24\u0026quot;\ravailability_zone = \u0026quot;us-east-1a\u0026quot;\rtags = {\rName = \u0026quot;private-subnet-vpc-main-1\u0026quot;\r}\r}\rresource \u0026quot;aws_subnet\u0026quot; \u0026quot;private-subnet-vpc-main-2\u0026quot; {\rvpc_id = aws_vpc.vpc-main.id\rcidr_block = \u0026quot;10.10.4.0/24\u0026quot;\ravailability_zone = \u0026quot;us-east-1b\u0026quot;\rtags = {\rName = \u0026quot;private-subnet-vpc-main-2\u0026quot;\r}\r}\r"
},
{
	"uri": "//localhost:1313/vi/3-migrate/3.1-setup-tools/3.1.1-create-ec2-instance/",
	"title": "Tạo Bastion host",
	"tags": [],
	"description": "",
	"content": "Step 1: Tuy cập Amazon EC2 console tại link https://console.aws.amazon.com/ec2/ -\u0026gt; Chọn Launch Instance.\nStep 2: Cấu hình EC2 Instance:\nName and tags: Bastion host, chọn AMI: EC2 Instance type: t2.small Cấu hình Network: Trong đó: Security Group gắn vào bastion cho phép các rule cần thiết để Instance Connect service có thể truy cập vào bastion\nStep 3: Chọn Review and Launch, sau đó chọn Launch\n"
},
{
	"uri": "//localhost:1313/vi/3-migrate/3.1-setup-tools/",
	"title": "Tạo Bastion Host và cài đặt các công cụ cần thiết",
	"tags": [],
	"description": "",
	"content": "Content Tạo Bastion host Tạo access key \u0026amp; secret key Setup Instance Connect để truy cập vào Bastion host thông qua giao thức ssh Cài đặt awscli tool Cài đặt eksctl tool Cài đặt kubectl tool Cài đặt Terraform tool "
},
{
	"uri": "//localhost:1313/vi/2-architecture/",
	"title": "Kiến trúc ",
	"tags": [],
	"description": "",
	"content": "Content Kiến trúc hiện tại của hệ thống Kubernetes trên môi trường on-premises Kiến trúc hệ thống khi được triển khai vào cụm AWS EKS "
},
{
	"uri": "//localhost:1313/vi/2-architecture/2.2-cloud/",
	"title": "Kiến trúc hệ thống khi được triển khai vào cụm AWS EKS",
	"tags": [],
	"description": "",
	"content": "\nĐây là Cơ sở hạ tầng trên môi trường AWS Cloud khi được di chuyển từ On-premises. Trên môi trường AWS Cloud, AWS chịu trách nhiệm quản lý Control Plane thay vì chúng ta phải tự quản lý Control Plane, đảm bảo tính high availability và các tình huống sao lưu \u0026amp; khôi phục khi xảy ra sự cố trên môi trường On-premises. Giảm gánh nặng quản lý cơ sở hạ tầng và giúp chúng ta tập trung vào phát triển ứng dụng.\nTrên môi trường AWS Cloud, người dùng sẽ truy cập Phonebook service bằng domain được phân giải bằng AWS Route53. Sau đó, requests sẽ đi đến Bộ cân bằng tải AWS được quản lý bởi AWS ALB Ingress Controller thay vì đi qua Ingress Controller Nginx trên môi trường On-premises, khi đó requests sẽ đi thẳng đến các Pod được triển khai trên worker node Team DevOps sẽ quản lý cụm AWS EKS bằng cách thực hiện các hành động trên server Bastion. Team DevOps sẽ truy cập server Bastion thông qua AWS Instance Connect\nChúng ta sẽ tiến hành di chuyển service từ môi trường On-premises sang môi trường AWS Cloud theo các bước sau:\nĐầu tiên, chúng ta sẽ tạo server Bastion và cài đặt các công cụ cần thiết để thực hiện apply code Terraform và quản lý cụm AWS EKS.\nTiếp theo, chúng ta sẽ xây dựng Cơ sở hạ tầng trên môi trường AWS Cloud (Sử dụng tool Infrastructure as code là Terraform)\nTiếp theo chúng ta sẽ triển khai kiến trúc của Phonebook App sử dụng nền tảng Kubernetes trên cluster EKS tương tự như kiến trúc của Phonebook App trên môi trường On-premises (Lúc này các service của công ty đã được triển khai lên cluster EKS, nhưng chưa có dữ liệu)\nCuối cùng, chúng ta sẽ triển khai sao lưu và khôi phục dữ liệu Ứng dụng trên môi trường On-premises vào cụm EKS\n"
},
{
	"uri": "//localhost:1313/vi/2-architecture/2.1-on-prem/2.1.2-k8s-app/",
	"title": "Kiến trúc ứng dụng được triển khai bằng Kubernetes trên môi trường on-premises",
	"tags": [],
	"description": "",
	"content": "\nKiến trúc ứng dụng danh bạ bao gồm 3 module (dịch vụ decouple):\nModule database: Lưu trữ dữ liệu trong cơ sở dữ liệu MySQL, được triển khai bằng StatefulSet, dữ liệu được lưu trữ trong static volume Module web-service: Chịu trách nhiệm triển khai các API Phonebook add/update/delete tương tác với module Cơ sở dữ liệu, được triển khai bằng cách sử dụng Deployment và tự động mở rộng quy mô bằng HPA (Horizontal Pod Autoscaling) Module result-service: Chịu trách nhiệm triển khai API search Phonebook để tương tác với module Dataabse, tương tự như module web-service Người dùng truy cập thông qua domain, Nginx Ingress Controller có trách nhiệm điều hướng các request theo các rule Ingress, các request sẽ được chuyển hướng đến Serivce và từ Service được chuyển hướng đến Pod.\n"
},
{
	"uri": "//localhost:1313/vi/4-backup-restore/4.2-push/",
	"title": "Push mysql backup file từ on-premises lên AWS cloud sử dụng awscli",
	"tags": [],
	"description": "",
	"content": "Để có thể push các object vào S3 bucket, chúng ta cần cài đặt awscli và cần configure các thông tin xác thực confiure (Tham khảo 3.1.4)\nChúng ta đã upload thành công, tiếp theo chúng ta sẽ khôi phục dữ liệu trên môi trường AWS Cloud\n"
},
{
	"uri": "//localhost:1313/vi/3-migrate/3.1-setup-tools/3.1.2-create-access-secret-key/",
	"title": "Tạo access key &amp; secret key",
	"tags": [],
	"description": "",
	"content": "Step 1: Truy cập vào AWS management console, click vào Profile name, và sau đó click vào Security Credentials Step 2: Đi đến Access Keys và chọn Create New Access Key. Step 3: Click vào Show Access Key và save/download the access key và secret access key. "
},
{
	"uri": "//localhost:1313/vi/3-migrate/3.2-terraform/3.2.2-igw/",
	"title": "Tạo AWS Internet Gateway bằng cách sử dụng Terraform",
	"tags": [],
	"description": "",
	"content": "Để cung cấp truy cập internet cho các service. Cần internet gateway trong VPC, Nó sẽ được sử dụng làm tuyến mặc định trong các public subnet\nresource \u0026quot;aws_internet_gateway\u0026quot; \u0026quot;internet-gateway-vpc-main\u0026quot; {\rvpc_id = aws_vpc.vpc-main.id\rtags = {\rName = \u0026quot;internet-gateway-vpc-main\u0026quot;\r}\r}\r"
},
{
	"uri": "//localhost:1313/vi/3-migrate/3.3-k8s-app/3.3.2-alb-ingress-manifest/",
	"title": "Tạo file ALB Ingress manifest",
	"tags": [],
	"description": "",
	"content": "Tạo Security Group cho AWS ALB bằng cách sử dụng Terraform\nresource \u0026quot;aws_security_group\u0026quot; \u0026quot;alb-security-group\u0026quot; {\rname = \u0026quot;alb-security-group\u0026quot;\rdescription = \u0026quot;Allow all inbound traffic and all outbound traffic\u0026quot;\rvpc_id = aws_vpc.vpc-main.id\ringress {\rfrom_port = 0\rto_port = 0\rprotocol = \u0026quot;-1\u0026quot;\rcidr_blocks = [\u0026quot;0.0.0.0/0\u0026quot;]\rdescription = \u0026quot;Allow all traffic from VPC main\u0026quot;\r} egress {\rfrom_port = 0\rto_port = 0\rprotocol = \u0026quot;-1\u0026quot;\rcidr_blocks = [\u0026quot;0.0.0.0/0\u0026quot;]\rdescription = \u0026quot;Allow all traffic outbound to VPC main\u0026quot;\r}\r}\rSau đó chạy lệnh terraform apply. ID của security group sẽ xuất hiện\nChúng ta sẽ sử dụng ID này để assign cho Ingress rule\nTiếp theo, Chúng ta cần tạo namepace cho App-phonebook bằng câu lệnh sau:\nkubectl create ns phonebook\rTạo manifest file để define Ingress rule cho web-server \u0026amp; result-server\nChỉ định các thuộc tính cho AWS ALB ingress\nFor web-server:\napiVersion: networking.k8s.io/v1\rkind: Ingress\rmetadata:\rname: web-server\rnamespace: phonebook\rannotations:\r# Ingress Core Settings\rkubernetes.io/ingress.class: \u0026quot;alb\u0026quot;\ralb.ingress.kubernetes.io/scheme: internet-facing\ralb.ingress.kubernetes.io/target-type: ip\ralb.ingress.kubernetes.io/tags: app=phonebook\ralb.ingress.kubernetes.io/subnets: subnet-030ff556cb14be7d9, subnet-09b6fd037c314a022\r# Health Check Settings\ralb.ingress.kubernetes.io/healthcheck-protocol: HTTP alb.ingress.kubernetes.io/healthcheck-port: traffic-port\ralb.ingress.kubernetes.io/healthcheck-path: /\ralb.ingress.kubernetes.io/healthcheck-interval-seconds: '15'\ralb.ingress.kubernetes.io/healthcheck-timeout-seconds: '5'\ralb.ingress.kubernetes.io/success-codes: '200'\ralb.ingress.kubernetes.io/healthy-threshold-count: '2'\ralb.ingress.kubernetes.io/unhealthy-threshold-count: '2'\ralb.ingress.kubernetes.io/security-groups: sg-0e21986c4e1c60ef8\rspec:\ringressClassName: \u0026quot;alb\u0026quot;\rrules:\r- http:\rpaths:\r- path: /\rpathType: Prefix\rbackend:\rservice:\rname: phonebook-service\rport:\rnumber: 80\rFor result-server\napiVersion: networking.k8s.io/v1\rkind: Ingress\rmetadata:\rname: result-server\rnamespace: phonebook\rannotations:\r# Ingress Core Settings\rkubernetes.io/ingress.class: \u0026quot;alb\u0026quot;\ralb.ingress.kubernetes.io/scheme: internet-facing\ralb.ingress.kubernetes.io/target-type: ip\ralb.ingress.kubernetes.io/tags: app=phonebook\ralb.ingress.kubernetes.io/subnets: subnet-030ff556cb14be7d9, subnet-09b6fd037c314a022\r# Health Check Settings\ralb.ingress.kubernetes.io/healthcheck-protocol: HTTP alb.ingress.kubernetes.io/healthcheck-port: traffic-port\ralb.ingress.kubernetes.io/healthcheck-path: /\ralb.ingress.kubernetes.io/healthcheck-interval-seconds: '15'\ralb.ingress.kubernetes.io/healthcheck-timeout-seconds: '5'\ralb.ingress.kubernetes.io/success-codes: '200'\ralb.ingress.kubernetes.io/healthy-threshold-count: '2'\ralb.ingress.kubernetes.io/unhealthy-threshold-count: '2'\ralb.ingress.kubernetes.io/security-groups: sg-0e21986c4e1c60ef8\rspec:\ringressClassName: alb\rrules:\r- http:\rpaths:\r- path: /\rpathType: Prefix\rbackend:\rservice:\rname: result-service\rport:\rnumber: 80 "
},
{
	"uri": "//localhost:1313/vi/3-migrate/3.2-terraform/",
	"title": "Xây dựng cơ sở hạ tầng trên AWS Cloud bằng Terraform",
	"tags": [],
	"description": "",
	"content": "Bắt đầu với Terraform. Đầu tiên, chúng ta cần tạo provider AWS. Nó cho phép tương tác với nhiều tài nguyên được AWS hỗ trợ, chẳng hạn như VPC, EC2, EKS và nhiều tài nguyên khác. Cần phải định cấu hình nhà cung cấp với thông tin xác thực phù hợp trước khi sử dụng.\nTrong trường hợp này, tôi sử dụng Access Key \u0026amp; Secret Key để định cấu hình thông tin xác thực cho Terraform\nprovider \u0026quot;aws\u0026quot; { region = \u0026quot;us-east-1\u0026quot; }\rterraform {\rrequired_providers {\raws = {\rsource = \u0026quot;hashicorp/aws\u0026quot;\rversion = \u0026quot;~\u0026gt; 3.0\u0026quot;\r}\r}\r}\rContent: Tạo AWS VPC \u0026amp; Subnets bằng cách sử dụng Terraform Tạo AWS Internet Gateway bằng cách sử dụng Terraform Tạo AWS NAT Gateway bằng cách sử dụng Terraform Tạo AWS Route Table bằng cách sử dụng Terraform Tạo AWS EKS cluster bằng cách sử dụng Terraform Tạo IAM OIDC provider EKS bằng cách sử dụng Terraform Truy cập vào cụm EKS "
},
{
	"uri": "//localhost:1313/vi/3-migrate/",
	"title": "Di chuyển service từ môi trường on-premises sang môi trường Cloud",
	"tags": [],
	"description": "",
	"content": "Content 3.1. Tạo Bastion Host và cài đặt các công cụ cần thiết 3.2. Xây dựng cơ sở hạ tầng trên AWS Cloud bằng Terraform 3.3. Triển khai kiến trúc ứng dụng Phonebook sử dụng nền tảng Kubernetes trên cụm AWS EKS trên AWS Cloud\n"
},
{
	"uri": "//localhost:1313/vi/3-migrate/3.3-k8s-app/3.3.3-web/",
	"title": "Module web server",
	"tags": [],
	"description": "",
	"content": "Tạo Configmap, secret\napiVersion: v1\rkind: ConfigMap\rmetadata:\rname: servers-configmap\rnamespace: phonebook\rdata:\rMYSQL_DATABASE_HOST: mysql-service.phonebook.svc.cluster.local\rMYSQL_USER: devenes\rMYSQL_DATABASE: phonebook\r---\rapiVersion: v1\rkind: Secret\rmetadata:\rname: mysql-secret\rnamespace: phonebook\rtype: Opaque\rdata:\rmysql-root-password: SjEyMzQ1ag==\r# value: J12345j\rmysql-admin-password: RGV2ZW5lc18x\r# value: Devenes_1\r---\rapiVersion: v1\rkind: ConfigMap\rmetadata:\rname: database-configmap\rnamespace: phonebook\rdata:\rMYSQL_USER: devenes\rMYSQL_DATABASE: phonebook\rTạo Configmap cho server: Chỉ định database cái mà server connect tới\napiVersion: v1\rkind: ConfigMap\rmetadata:\rname: servers-configmap\rnamespace: phonebook\rdata:\rMYSQL_DATABASE_HOST: mysql-service.phonebook.svc.cluster.local\rMYSQL_USER: devenes\rMYSQL_DATABASE: phonebook\rTạo Deployment \u0026amp; Service type “ClusterIP” cho web-server\napiVersion: apps/v1\rkind: Deployment\rmetadata:\rname: phonebook-app-deploy\rnamespace: phonebook\rlabels:\rapp: phonebook-app-deploy\rspec:\rreplicas: 1\rselector:\rmatchLabels:\rname: phonebook-app-pod\rtemplate:\rmetadata:\rname: phonebook-app-pod\rlabels:\rname: phonebook-app-pod\rspec:\rcontainers:\r- name: phonebook-app\rresources:\rlimits:\rcpu: 200m\rmemory: 400Mi\rrequests:\rcpu: 200m\rmemory: 400Mi\rimage: devenes/python_web_server:2\rports:\r- containerPort: 80\renv:\r- name: MYSQL_PASSWORD\rvalueFrom:\rsecretKeyRef:\rname: mysql-secret\rkey: mysql-admin-password\renvFrom:\r- configMapRef:\rname: servers-configmap\r---\rapiVersion: v1\rkind: Service\rmetadata:\rname: phonebook-service\rnamespace: phonebook\rlabels:\rname: phonebook-service\rspec:\rtype: ClusterIP\rports:\r- port: 80\rtargetPort: 80\rselector:\rname: phonebook-app-pod\rTạo HorizontalPodAutoscaler để auto scale web-server Pod, nó thực hiện action scale CPU khi mà CPU đạt 50%. (Đảm bảo Metric Server đã được cài đặt)\napiVersion: autoscaling/v1\rkind: HorizontalPodAutoscaler\rmetadata:\rname: hpa-deploy-web-server\rnamespace: phonebook\rspec:\rscaleTargetRef:\rapiVersion: apps/v1\rkind: Deployment\rname: phonebook-app-deploy\rminReplicas: 1\rmaxReplicas: 10\rtargetCPUUtilizationPercentage: 50\r"
},
{
	"uri": "//localhost:1313/vi/4-backup-restore/4.3-restore/",
	"title": "Restore dữ liệu mysql trên môi trường AWS cloud",
	"tags": [],
	"description": "",
	"content": "Tương tự như môi trường on-premises, chúng tôi kéo tệp từ S3 bucket và sao chép tệp vào thư mục /mnt/data trên server. Sau đó truy cập MySQL Pod và khôi phục bằng lệnh:\nmysql -u root -p phonebook \u0026lt; database_ phonebook.sql Sau khi quá trình restore hoàn tất, chúng ta kiểm tra lại dữ liệu trên môi trường Cloud:\nChúng ta đã thấy rằng dữ liệu đã được restore thành công.\nVậy là chúng ta đã di chuyển thành công service được triển khai bằng Kubernetes từ môi trường on-premises lên môi trường Cloud.\n"
},
{
	"uri": "//localhost:1313/vi/3-migrate/3.1-setup-tools/3.1.3-instance-connect/",
	"title": "Setup Instance Connect để truy cập vào Bastion host thông qua giao thức ssh",
	"tags": [],
	"description": "",
	"content": "Kết nối Amazon EC2 instance là một cách đơn giản và an toàn để kết nối với các instance bằng Secure Shell (SSH). Với EC2 Instance Connect, ta có thể kiểm soát quyền truy cập SSH vào instance của mình bằng policy AWS Identity and Access Management (IAM) cũng như kiểm tra các yêu cầu kết nối bằng event AWS CloudTrail.\nĐể AWS Instance Connect có thể truy cập Bastion Host, Bastion Host phải được đặt trên public subnet và security group phải mở Inbound cho dải IP: https://ip-ranges.amazonaws.com/ ip-ranges.json Để kết nối với instance bằng browser-based client từ bảng điều khiển Amazon EC2:\nStep 1: Chọn instance và chọn Connect. Step 2: Click vào Connect: Chúng ta đã truy cập thành công Bastion Host bằng cách sử dụng AWS EC2 Instance Connect: Từ đây chúng ta sẽ bắt đầu cài đặt các công cụ cần thiết cho bastion host\n"
},
{
	"uri": "//localhost:1313/vi/3-migrate/3.2-terraform/3.2.3-nat/",
	"title": "Tạo AWS NAT Gateway bằng cách sử dụng Terraform",
	"tags": [],
	"description": "",
	"content": "NAT Gateway được sử dụng trong các private subnet để cho phép service kết nối với internet. Đối với NAT, trước tiên cần allocate public IP address first.\nresource \u0026quot;aws_eip\u0026quot; \u0026quot;eip-vpc-main\u0026quot; {\rvpc = true\rtags = {\rName = \u0026quot;eip-vpc-main\u0026quot;\r}\r}\rresource \u0026quot;aws_nat_gateway\u0026quot; \u0026quot;nat-gateway-vpc-main\u0026quot; {\rallocation_id = aws_eip.eip-vpc-main.id\rsubnet_id = aws_subnet.public-subnet-vpc-main-1.id\rconnectivity_type = \u0026quot;public\u0026quot;\rtags = {\rName = \u0026quot;nat-gateway-vpc-main\u0026quot;\r}\r# Internet Gateway must be created before aws_nat_gateway\rdepends_on = [aws_internet_gateway.internet-gateway-vpc-main]\r}\r"
},
{
	"uri": "//localhost:1313/vi/3-migrate/3.3-k8s-app/",
	"title": "Triển khai kiến trúc ứng dụng Phonebook sử dụng nền tảng Kubernetes trên cụm AWS EKS trên AWS Cloud",
	"tags": [],
	"description": "",
	"content": "Content: AWS ALB Ingress Controller Tạo file ALB Ingress manifest Module web server Module result server Module MySQL database "
},
{
	"uri": "//localhost:1313/vi/4-backup-restore/",
	"title": "Backup &amp; restore dữ liệu ứng dụng từ môi trường on-premises lên AWS cloud",
	"tags": [],
	"description": "",
	"content": "Tùy vào dữ liệu của ứng dụng lớn hay nhỏ và yêu cầu thời gian upload dữ liệu ngắn hay dài mà chúng ta sẽ lựa chọn các kịch bản sao lưu \u0026amp; khôi phục khác nhau.\nVới ứng dụng này, chúng ta sẽ sử dụng mysqldump để sao lưu cơ sở dữ liệu App-phonebook trên môi trường On-premises, sau đó đẩy nó lên S3 bucket để server trên môi trường AWS Cloud có thể kéo về. Cuối cùng khôi phục trên cơ sở dữ liệu mysql đã triển khai trên AWS Cloud\nContent: Backup mysql database trên môi trường on-premises Push mysql backup file từ on-premises lên AWS cloud sử dụng awscli Restore dữ liệu mysql trên môi trường AWS cloud "
},
{
	"uri": "//localhost:1313/vi/3-migrate/3.1-setup-tools/3.1.4-awscli/",
	"title": "Cài đặt awscli tool",
	"tags": [],
	"description": "",
	"content": "Step 1: Cập nhật chỉ mục gói cục bộ và cung cấp cho hệ thống thông tin mới nhất về các gói có sẵn từ repo\nsudo apt update -y Step 2: Download awscli binary file\ncurl \u0026quot;https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\u0026quot; -o \u0026quot;awscliv2.zip\u0026quot;\rStep 3: unzip sau đó install\nunzip awscliv2.zip\rsudo ./aws/install\rStep 4: Cấu hình cho AWS CLI\naws configure\raws_access_key_id = xxx\raws_secret_access_key = xxx\rregion = xxx\routput = xxx\r"
},
{
	"uri": "//localhost:1313/vi/3-migrate/3.3-k8s-app/3.3.4-result/",
	"title": "Module result server",
	"tags": [],
	"description": "",
	"content": "Tạo Deployment \u0026amp; Service type “ClusterIP” cho result-server\napiVersion: apps/v1\rkind: Deployment\rmetadata:\rname: result-app-deploy\rnamespace: phonebook\rlabels:\rname: result-app-deploy\rspec:\rreplicas: 1\rselector:\rmatchLabels:\rname: result-app-pod\rtemplate:\rmetadata:\rname: result-app-pod\rlabels:\rname: result-app-pod\rspec:\rcontainers:\r- name: result-app\rresources:\rimage: devenes/python_result_server:2\rports:\r- containerPort: 80\renv:\r- name: MYSQL_PASSWORD\rvalueFrom:\rsecretKeyRef:\rname: mysql-secret\rkey: mysql-admin-password\renvFrom:\r- configMapRef:\rname: servers-configmap\r---\rapiVersion: v1\rkind: Service\rmetadata:\rname: result-service\rnamespace: phonebook\rlabels:\rname: result-service\rspec:\rtype: ClusterIP\rports:\r- port: 80\rtargetPort: 80\rselector:\rname: result-app-pod\rTạo HorizontalPodAutoscaler để auto scale web-server Pod, nó thực hiện action scale CPU khi mà CPU đạt 50%. (Đảm bảo Metric Server đã được cài đặt)\napiVersion: autoscaling/v1\rkind: HorizontalPodAutoscaler\rmetadata:\rname: hpa-deploy-result-server\rnamespace: phonebook\rspec:\rscaleTargetRef:\rapiVersion: apps/v1\rkind: Deployment\rname: result-app-deploy\rminReplicas: 1\rmaxReplicas: 10\rtargetCPUUtilizationPercentage: 50\r"
},
{
	"uri": "//localhost:1313/vi/3-migrate/3.2-terraform/3.2.4-routetable/",
	"title": "Tạo AWS Route Table bằng cách sử dụng Terraform",
	"tags": [],
	"description": "",
	"content": "A route table chứa một bộ quy tắc, được gọi là các route, xác định nơi lưu lượng truy cập mạng từ subnet or gateway được hướng tới\nRoute Table for Public Subnets\nresource \u0026quot;aws_route_table\u0026quot; \u0026quot;route-table-public-vpc-main\u0026quot; {\rvpc_id = aws_vpc.vpc-main.id\rroute {\rcidr_block = \u0026quot;0.0.0.0/0\u0026quot;\rgateway_id = aws_internet_gateway.internet-gateway-vpc-main.id\r}\rtags = {\rName = \u0026quot;route-table-public-vpc-main\u0026quot;\r}\r}\rresource \u0026quot;aws_route_table_association\u0026quot; \u0026quot;public-subnet-1\u0026quot; {\rsubnet_id = aws_subnet.public-subnet-vpc-main-1.id\rroute_table_id = aws_route_table.route-table-public-vpc-main.id\r}\rresource \u0026quot;aws_route_table_association\u0026quot; \u0026quot;public-subnet-2\u0026quot; {\rsubnet_id = aws_subnet.public-subnet-vpc-main-2.id\rroute_table_id = aws_route_table.route-table-public-vpc-main.id\r}\rRoute Table for Private Subnets\nresource \u0026quot;aws_route_table\u0026quot; \u0026quot;route-table-private-vpc-main\u0026quot; {\rvpc_id = aws_vpc.vpc-main.id\rroute {\rcidr_block = \u0026quot;0.0.0.0/0\u0026quot;\rnat_gateway_id = aws_nat_gateway.nat-gateway-vpc-main.id\r}\rtags = {\rName = \u0026quot;route-table-private-vpc-main\u0026quot;\r}\r}\rresource \u0026quot;aws_route_table_association\u0026quot; \u0026quot;private-subnet-1\u0026quot; {\rsubnet_id = aws_subnet.private-subnet-vpc-main-1.id\rroute_table_id = aws_route_table.route-table-private-vpc-main.id\r}\rresource \u0026quot;aws_route_table_association\u0026quot; \u0026quot;private-subnet-2\u0026quot; {\rsubnet_id = aws_subnet.private-subnet-vpc-main-2.id\rroute_table_id = aws_route_table.route-table-private-vpc-main.id\r} "
},
{
	"uri": "//localhost:1313/vi/3-migrate/3.1-setup-tools/3.1.5-eksctl/",
	"title": "Cài đặt eksctl tool",
	"tags": [],
	"description": "",
	"content": "Step 1: Chỉ định biến môi trường cho ARM systems, set ARCH: arm64, armv6 or armv7\nARCH=amd64\rPLATFORM=$(uname -s)_$ARCH\rStep 2: Download eksctl-install file\ncurl -sLO \u0026quot;https://github.com/eksctl-io/eksctl/releases/latest/download/eksctl_$PLATFORM.tar.gz\u0026quot;\r(Optional) Verify checksum\rcurl -sL \u0026quot;https://github.com/eksctl-io/eksctl/releases/latest/download/eksctl_checksums.txt\u0026quot; | grep $PLATFORM | sha256sum --check\rStep 3: Giải nén sau đó move vào folder bin\ntar -xzf eksctl_$PLATFORM.tar.gz -C /tmp \u0026amp;\u0026amp; rm eksctl_$PLATFORM.tar.gz\rsudo mv /tmp/eksctl /usr/local/bin\r"
},
{
	"uri": "//localhost:1313/vi/5-clear/",
	"title": "Dọn dẹp tài nguyên",
	"tags": [],
	"description": "",
	"content": "Vì tất cả tài nguyên, ứng dụng Phonebook, dữ liệu ứng dụng đều được triển khai trên môi trường AWS Cloud nên sau khi hoàn thành Workshop này, nếu muốn dọn sạch tài nguyên, chúng ta chỉ cần chạy lệnh: terraform destroy và nhập yes. Khi đó quá trình dọn dẹp tài nguyên sẽ diễn ra tự động:\nQuá trình sẽ tiếp tục cho đến khi tài nguyên do Terraform tạo ra được xóa hoàn toàn\n"
},
{
	"uri": "//localhost:1313/vi/3-migrate/3.3-k8s-app/3.3.5-mysql/",
	"title": "Module MySQL database",
	"tags": [],
	"description": "",
	"content": "Tạo Static Volume: Tạo PersistentVolumeClaim bound vào PersistentVolume\napiVersion: v1\rkind: PersistentVolume\rmetadata:\rname: mysql-pv-volume\rnamespace: phonebook\rlabels:\rtype: local\rspec:\rstorageClassName: manual\rcapacity:\rstorage: 2Gi\raccessModes:\r- ReadWriteOnce\rhostPath:\rpath: \u0026quot;/mnt/data\u0026quot;\r---\rapiVersion: v1\rkind: PersistentVolumeClaim\rmetadata:\rname: mysql-pv-claim\rnamespace: phonebook\rspec:\rstorageClassName: manual\raccessModes:\r- ReadWriteOnce\rresources:\rrequests:\rstorage: 2Gi\rTạo StatefulSet \u0026amp; Service type “ClusterIP” cho mysql database: Chỉ định static volume và configmap \u0026amp; secret được khởi tạo ở trên\napiVersion: apps/v1\rkind: StatefulSet\rmetadata:\rname: mysql-deploy\rnamespace: phonebook\rlabels:\rname: mysql-deploy\rspec:\rreplicas: 1\rserviceName: mysql-service\rselector:\rmatchLabels:\rname: mysql-pod\rtemplate:\rmetadata:\rname: mysql-pod\rlabels:\rname: mysql-pod\rspec: containers:\r- image: mysql:5.7\rresources:\rname: mysql\rimagePullPolicy: Always\renv:\r- name: MYSQL_PASSWORD\rvalueFrom:\rsecretKeyRef:\rname: mysql-secret\rkey: mysql-admin-password\r- name: MYSQL_ROOT_PASSWORD\rvalueFrom:\rsecretKeyRef:\rname: mysql-secret\rkey: mysql-root-password\renvFrom:\r- configMapRef:\rname: database-configmap\rports:\r- containerPort: 3306\rvolumeMounts:\r- name: mysql-persistent-storage\rmountPath: /var/lib/mysql\rvolumes:\r- name: mysql-persistent-storage\rpersistentVolumeClaim:\rclaimName: mysql-pv-claim\r---\rapiVersion: v1\rkind: Service\rmetadata:\rname: mysql-service\rnamespace: phonebook\rlabels:\rname: mysql-service\rspec:\rports:\r- port: 3306\rtargetPort: 3306\rselector:\rname: mysql-pod\rChúng ta đã chuẩn bị file manifest để define architecture của Phonebook App trên môi trường AWS Cloud. Để triển khai, chúng ta sẽ chạy câu lệnh sau:\nkubectl apply --f app-phonebook/. Trong đó app-phonebook là folder chứa file manifest. Chúng ta đã triển khai thành công Phonebook App trên EKS Cluster:\nApplication interface:\nAdd/Update/Delete phone book APIs:\nResult phone book APIs:\nTại thời điểm này, service của công ty đã được triển khai vào cụm EKS nhưng chưa có dữ liệu. Chúng ta cần sao lưu và khôi phục dữ liệu Ứng dụng từ môi trường On-premises lên cụm EKS\n"
},
{
	"uri": "//localhost:1313/vi/3-migrate/3.2-terraform/3.2.5-eks-cluster/",
	"title": "Tạo AWS EKS cluster bằng cách sử dụng Terraform",
	"tags": [],
	"description": "",
	"content": "Các cụm Kubernetes do Amazon EKS quản lý thực hiện lệnh gọi API đến các AWS services khác để quản lý tài nguyên mà chúng tôi sử dụng với dịch vụ. Ví dụ: EKS sẽ tạo một Auto scaling cho từng Instance nếu bạn sử dụng các Node Group được quản lý.\nTrước khi tạo Amazon EKS clusters, ta bắt buộc phải tạo IAM role với AmazonEKSClusterPolicy.\nresource \u0026quot;aws_iam_role\u0026quot; \u0026quot;eks-cluster-role\u0026quot; {\rname = \u0026quot;eks-cluster-role\u0026quot;\rassume_role_policy = \u0026lt;\u0026lt;POLICY\r{\r\u0026quot;Version\u0026quot;: \u0026quot;2012-10-17\u0026quot;,\r\u0026quot;Statement\u0026quot;: [\r{\r\u0026quot;Effect\u0026quot;: \u0026quot;Allow\u0026quot;,\r\u0026quot;Principal\u0026quot;: {\r\u0026quot;Service\u0026quot;: \u0026quot;eks.amazonaws.com\u0026quot;\r},\r\u0026quot;Action\u0026quot;: \u0026quot;sts:AssumeRole\u0026quot;\r}\r]\r}\rPOLICY\r}\rresource \u0026quot;aws_iam_role_policy_attachment\u0026quot; \u0026quot;eks-cluster-role-attach-AmazonEKSClusterPolicy\u0026quot; {\rpolicy_arn = \u0026quot;arn:aws:iam::aws:policy/AmazonEKSClusterPolicy\u0026quot;\rrole = aws_iam_role.eks-cluster-role.name\r}\rresource \u0026quot;aws_eks_cluster\u0026quot; \u0026quot;phonebook-eks-cluster\u0026quot; {\rname = \u0026quot;phonebook-eks-cluster\u0026quot;\rrole_arn = aws_iam_role.eks-cluster-role.arn\rvpc_config {\rsubnet_ids = [\raws_subnet.private-subnet-vpc-main-1.id,\raws_subnet.private-subnet-vpc-main-2.id,\raws_subnet.public-subnet-vpc-main-1.id,\raws_subnet.public-subnet-vpc-main-2.id\r]\r}\rtags = {\rApp = \u0026quot;phonebook\u0026quot;\r}\rdepends_on = [aws_iam_role_policy_attachment.eks-cluster-role-attach-AmazonEKSClusterPolicy]\r}\rTiếp theo ta tạo Node Group cho EKS cluster. Tuy nhiên, trước khi tạo Node Group thì chúng ta cần attach các policy cần thiết vào role\nresource \u0026quot;aws_iam_role\u0026quot; \u0026quot;node-group-role\u0026quot; {\rname = \u0026quot;node-group-role\u0026quot;\rassume_role_policy = jsonencode({\rStatement = [{\rAction = \u0026quot;sts:AssumeRole\u0026quot;\rEffect = \u0026quot;Allow\u0026quot;\rPrincipal = {\rService = \u0026quot;ec2.amazonaws.com\u0026quot;\r}\r}]\rVersion = \u0026quot;2012-10-17\u0026quot;\r})\r}\rresource \u0026quot;aws_iam_role_policy_attachment\u0026quot; \u0026quot;node-group-role-attach-AmazonEKSWorkerNodePolicy\u0026quot; {\rpolicy_arn = \u0026quot;arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy\u0026quot;\rrole = aws_iam_role.node-group-role.name\r}\rresource \u0026quot;aws_iam_role_policy_attachment\u0026quot; \u0026quot;node-group-role-attach-AmazonEKS_CNI_Policy\u0026quot; {\rpolicy_arn = \u0026quot;arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy\u0026quot;\rrole = aws_iam_role.node-group-role.name\r}\rresource \u0026quot;aws_iam_role_policy_attachment\u0026quot; \u0026quot;node-group-role-attach-AmazonEC2ContainerRegistryReadOnly\u0026quot; {\rpolicy_arn = \u0026quot;arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly\u0026quot;\rrole = aws_iam_role.node-group-role.name\r}\rresource \u0026quot;aws_iam_role_policy_attachment\u0026quot; \u0026quot;node-group-role-attach-AmazonS3FullAccess\u0026quot; {\rpolicy_arn = \u0026quot;arn:aws:iam::aws:policy/AmazonS3FullAccess\u0026quot;\rrole = aws_iam_role.node-group-role.name\r}\rresource \u0026quot;aws_iam_role_policy_attachment\u0026quot; \u0026quot;node-group-role-attach-AmazonEC2FullAccess\u0026quot; {\rpolicy_arn = \u0026quot;arn:aws:iam::aws:policy/AmazonEC2FullAccess\u0026quot;\rrole = aws_iam_role.node-group-role.name\r}\rTiếp theo chúng ta viết code Terraform để tạo Node Group với: - Tên Node Group là \u0026ldquo;phonebook-nodes\u0026rdquo; nằm trong \u0026ldquo;phonebook-eks-cluster\u0026rdquo; EKS cluster - Network là Private-subnet-vpc-main-1\n- ami là Amazon Linux 2 x86_64, capacity type là on demand, instance type là t2.medium và disk storage là 10Gib - scaling config: desired = 1, max = 1 \u0026amp; min = 1\nresource \u0026quot;aws_eks_node_group\u0026quot; \u0026quot;phonebook-nodes\u0026quot; {\rcluster_name = aws_eks_cluster.phonebook-eks-cluster.name\rnode_group_name = \u0026quot;phonebook-nodes\u0026quot;\rnode_role_arn = aws_iam_role.node-group-role.arn\rsubnet_ids = [\raws_subnet.private-subnet-vpc-main-1.id\r]\r# Node group compute configuration\rami_type = \u0026quot;AL2_x86_64\u0026quot;\rcapacity_type = \u0026quot;ON_DEMAND\u0026quot;\rinstance_types = [\u0026quot;t2.medium\u0026quot;]\rdisk_size = 10\rscaling_config {\rdesired_size = 1\rmax_size = 1\rmin_size = 1\r}\r# Node group update configuration\rupdate_config {\rmax_unavailable = 1\r}\rlabels = {\rapp = \u0026quot;phonebook\u0026quot;\r}\rdepends_on = [\raws_iam_role_policy_attachment.node-group-role-attach-AmazonEKSWorkerNodePolicy,\raws_iam_role_policy_attachment.node-group-role-attach-AmazonEKS_CNI_Policy,\raws_iam_role_policy_attachment.node-group-role-attach-AmazonEC2ContainerRegistryReadOnly,\raws_iam_role_policy_attachment.node-group-role-attach-AmazonS3FullAccess,\raws_iam_role_policy_attachment.node-group-role-attach-AmazonEC2FullAccess\r]\r} "
},
{
	"uri": "//localhost:1313/vi/3-migrate/3.1-setup-tools/3.1.6-kubectl/",
	"title": "Cài đặt kubectl tool",
	"tags": [],
	"description": "",
	"content": "Step 1: Download binary file\ncurl -LO https://dl.k8s.io/release/v1.28.4/bin/linux/amd64/kubectl\rStep 2: Install kubectl\nsudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl\rStep 3: Lệnh check version của kubectl\nkubectl version --client\r"
},
{
	"uri": "//localhost:1313/vi/3-migrate/3.2-terraform/3.2.6-oidc/",
	"title": "Tạo IAM OIDC provider EKS bằng cách sử dụng Terraform",
	"tags": [],
	"description": "",
	"content": "Để quản lý quyền cho các ứng dụng được triển khai trong Kubernetes. Chúng ta có thể attach policy trực tiếp vào các node Kubernetes. Trong trường hợp đó, Node Group sẽ có cùng quyền truy cập vào tài nguyên AWS. Hoặc chúng ta có thể tạo nhà cung cấp kết nối OpenID, nhà cung cấp này sẽ cho phép cấp quyền IAM dựa trên service account sử dụng bởi pod..\nOpenID Connect là một giao thức xác thực cho phép xác minh danh tính người dùng khi người dùng đang cố truy cập điểm cuối HTTP được bảo vệ. OIDC là sự phát triển tiến hóa của các ý tưởng được triển khai trước đó trong OAuth và OpenID.\ndata \u0026quot;tls_certificate\u0026quot; \u0026quot;eks\u0026quot; {\rurl = aws_eks_cluster.phonebook-eks-cluster.identity[0].oidc[0].issuer }\rresource \u0026quot;aws_iam_openid_connect_provider\u0026quot; \u0026quot;eks\u0026quot; {\rclient_id_list = [\u0026quot;sts.amazonaws.com\u0026quot;]\rthumbprint_list = [data.tls_certificate.eks.certificates[0].sha1_fingerprint]\rurl = aws_eks_cluster.phonebook-eks-cluster.identity[0].oidc[0].issuer\r}\rChúng ta hoàn thành việc tạo file main.tf, sau đó chúng ta sẽ chạy lệnh apply code Terraform\nterraform init: khởi tạo một thư mục làm việc và tải xuống các plugin và mô-đun nhà cung cấp cần thiết, đồng thời thiết lập phần phụ trợ để lưu trữ trạng thái cơ sở hạ tầng của bạn\nterraform plan: tạo một lần chạy thử, xác định những hành động nào là cần thiết để đạt được trạng thái mong muốn được xác định trong tệp cấu hình Terraform\nterraform apply: để triển khai lên AWS cloud\nNhập yes, sau AWS resources bắt đầu được khởi tạo\nChúng tôi đã hoàn thành việc tạo Cơ sở hạ tầng trên môi trường AWS Cloud bằng Terraform (Infrasture as code tool)\n"
},
{
	"uri": "//localhost:1313/vi/3-migrate/3.1-setup-tools/3.1.7-terraform/",
	"title": "Cài đặt Terraform tool",
	"tags": [],
	"description": "",
	"content": "Refer: https://developer.hashicorp.com/terraform/tutorials/aws-get-started/install-cli\nStep 1: Đảm bảo rằng hệ thống của bạn được cập nhật và bạn đã cài đặt:\ninstalled the gnupg software-properties-common curl packages Bạn sẽ sử dụng các gói này để xác minh chữ ký GPG của HashiCorp và cài đặt kho gói Debian của HashiCorp.\nsudo apt-get update -y \u0026amp;\u0026amp; sudo apt-get install -y gnupg software-properties-common\rStep 2: Cài đặt the HashiCorp GPG key.\nwget -O- https://apt.releases.hashicorp.com/gpg | \\\rgpg --dearmor | \\\rsudo tee /usr/share/keyrings/hashicorp-archive-keyring.gpg \u0026gt; /dev/null\rStep 3: Xác minh the key\u0026rsquo;s fingerprint.\ngpg --no-default-keyring \\\r--keyring /usr/share/keyrings/hashicorp-archive-keyring.gpg \\\r--fingerprint\rThe gpg command will report the key fingerprint:\r/usr/share/keyrings/hashicorp-archive-keyring.gpg\r-------------------------------------------------\rpub rsa4096 XXXX-XX-XX [SC]\rAAAA AAAA AAAA AAAA\ruid [ unknown] HashiCorp Security (HashiCorp Package Signing) \u0026lt;security+packaging@hashicorp.com\u0026gt;\rsub rsa4096 XXXX-XX-XX [E]\rStep 4: Add the official HashiCorp repository vào hệ thống\nThe lsb_release -cs command finds the distribution release codename for your current system, such as buster, groovy, or sid.\necho \u0026quot;deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] \\\rhttps://apt.releases.hashicorp.com $(lsb_release -cs) main\u0026quot; | \\\rsudo tee /etc/apt/sources.list.d/hashicorp.list\rStep 5: Download the package information from HashiCorp.\nsudo apt update -y\rStep 6: Install Terraform from the new repository.\nsudo apt-get install terraform -y\r*** Verify the installation\nterraform --help\r*** Add any subcommand to terraform -help to learn more about what it does and available options.\nterraform --help plan\r"
},
{
	"uri": "//localhost:1313/vi/3-migrate/3.2-terraform/3.2.7-access-eks-cluster/",
	"title": "Truy cập vào cụm EKS",
	"tags": [],
	"description": "",
	"content": "Để có thể truy cập vào cụm EKS thì ta cần cài đặt aws-iam-authenticator trên bastion host, sau đó update kubeconfig AWS IAM Authenticator là một command-line tool giúp quản lý xác thực truy cập cụm cho Amazon Elastic Container Service for Kubernetes (EKS)\nBằng cách tận dụng IAM Authenticator, người dùng có thể xác thực dựa trên AWS IAM credentials và sử dụng liền mạch các khả năng mạnh mẽ của EKS. Điều này giúp đơn giản hóa quy trình xác thực và giúp duy trì môi trường an toàn và dễ quản lý cho các cụm Kubernetes.\n# Download binary file\rcurl -o aws-iam-authenticator https://amazon-eks.s3.us-west-2.amazonaws.com/1.15.10/2020-02-22/bin/linux/amd64/aws-iam-authenticator\r# Add EXECUTE permission\rchmod +x ./aws-iam-authenticator\r# Move binary file to folder bin\rsudo mv ./aws-iam-authenticator /usr/local/bin\rTiếp theo, update kubeconfig bằng command:\naws eks update-kubeconfig --name phonebook-eks-cluster\rSau khi chạy câu lệnh trên, kubeconfig file được update trong folder /root/.kube/config. Chúng ta giờ đây có thể quản lý cụm EKS bằng kubectl tool\n"
},
{
	"uri": "//localhost:1313/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]